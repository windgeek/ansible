CREATE DATABASE IF NOT EXISTS k19_ods;


-- CREATE TABLE k19_ods.k19_dm_log_monitor_local ( time_string String,  time_second Int64,  ip String,  region String,  action String,  file_name String,  file_size Int64,  uuid String,  data_type String) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(time_second)) ORDER BY time_second TTL toDateTime(time_second) + toIntervalDay(90) SETTINGS index_granularity = 8192;

CREATE TABLE k19_ods.oss_monitor_log_local (`starttime_readable` DateTime MATERIALIZED toDateTime(start_time / 1000), `category` LowCardinality(String), `region` LowCardinality(String), `server_ip` String, `start_time` Int64, `file_count` UInt32, `file_size` UInt64) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(start_time / 1000)) ORDER BY (starttime_readable, category, region, server_ip) TTL toDateTime(starttime_readable) + toIntervalDay(90) SETTINGS index_granularity = 8192;
--CREATE TABLE k19_ods.ntc_oss_monitor_log_local (`region` LowCardinality(String), `starttime_readable` DateTime, `deal_time` Int64, `file_name` String, `file_size` UInt32, `client_ip` String, `server_ip` String, `start_time` Int64, `end_time` Int64, `state` LowCardinality(String), `category` LowCardinality(String), `filter_type` LowCardinality(String), `file_type` LowCardinality(String)) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(start_time / 1000)) ORDER BY start_time TTL toDateTime(start_time) + toIntervalDay(7) SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.oss_ratelimiter_log_local(`region` LowCardinality(String),`starttime_readable` DateTime,`start_time` UInt64, `client_host` String,`client_port` String,`remote_host` String,`remote_port` String,`file_type` LowCardinality(String)) ENGINE = MergeTree PARTITION BY toYYYYMM(starttime_readable) ORDER BY (starttime_readable,file_type,region) TTL starttime_readable + toIntervalDay(90) SETTINGS index_granularity = 8192;
-- CREATE TABLE k19_ods.ntc_oss_monitor_state_local (`monitor_time` UInt64, `state_code` Int8, `state_msg` String) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(monitor_time)) ORDER BY monitor_time SETTINGS index_granularity = 8192;
-- CREATE MATERIALIZED  VIEW k19_ods.table_oss_category_region_view_local( `start_time` DateTime,`category` LowCardinality(String),`region` LowCardinality(String),`file_size` UInt32,counts UInt32) ENGINE=SummingMergeTree((file_size,counts)) PARTITION BY toYYYYMM(start_time) ORDER BY (start_time,category,region) TTL start_time + toIntervalDay(90) POPULATE AS SELECT starttime_readable AS start_time,category,region,file_size,1 AS counts FROM k19_ods.ntc_oss_monitor_log_local;
-- CREATE MATERIALIZED  VIEW k19_ods.table_oss_server_ip_region_view_local( `start_time` DateTime,`region` LowCardinality(String),`server_ip` LowCardinality(String),`file_size` UInt32,counts UInt32) ENGINE=SummingMergeTree((file_size,counts)) PARTITION BY toYYYYMM(start_time) ORDER BY (start_time,region,server_ip)TTL start_time + toIntervalDay(90) POPULATE AS SELECT starttime_readable AS start_time,region,server_ip,file_size,1 AS counts FROM k19_ods.ntc_oss_monitor_log_local;
-- CREATE MATERIALIZED  VIEW k19_ods.table_oss_file_name_view_local(start_time DateTime, file_name String,counts UInt32) ENGINE=SummingMergeTree((counts)) PARTITION BY toYYYYMMDD(start_time) ORDER BY (file_name) TTL start_time + toIntervalDay(7)POPULATE AS SELECT toDateTime(toDate(starttime_readable)) AS start_time,file_name,1 AS counts FROM k19_ods.ntc_oss_monitor_log_local;


--数据流监控
CREATE TABLE k19_ods.spark_exception_log_local (`createTime` DateTime, `exceptionDesc` String, `exceptionType` String, `size` Int64, `region` String, `topicName` String, `exceptionNumber` String) ENGINE = MergeTree() PARTITION BY toRelativeDayNum(createTime) ORDER BY createTime TTL toDateTime(createTime) + toIntervalDay(90) SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.spark_monitor_log_local (`region` String, `job_id` String, `job_name` String, `state` Int8, `start_time` Datetime, `finish_time` Datetime, `url` String, `found_time` Int64) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.yarn_monitor_log_local (`region` String, `found_time` Int64, `appsSubmitted` Int32, `appsCompleted` Int32, `appsPending` Int32, `appsRunning` Int32, `appsFailed` Int32, `appsKilled` Int32, `reservedMB` Int32, `availableMB` Int32, `allocatedMB` Int32, `reservedVirtualCores` Int32, `availableVirtualCores` Int32, `allocatedVirtualCores` Int32, `containersAllocated` Int32, `containersReserved` Int32, `containersPending` Int32, `totalMB` Int32, `totalVirtualCores` Int32, `totalNodes` Int32, `lostNodes` Int32, `unhealthyNodes` Int32, `decommissionedNodes` Int32, `rebootedNodes` Int32, `activeNodes` Int32) ENGINE = MergeTree PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192;

CREATE TABLE k19_ods.ck_slow_query_local (`eventDate` Date, `startTime` DateTime, `status` LowCardinality(String), `useSeconds` Float64, `readRows` UInt64, `resultRows` UInt64, `writeRows` UInt64, `writtenMB` Float64, `memoryUsageMB` Float64, `tableName` LowCardinality(String),`clusterName` LowCardinality(String), `serverName` LowCardinality(String), `serverIp` LowCardinality(String), `initial_query_id` UUID, `query_id` UUID, `queryFromHost` LowCardinality(String), `query` String,exception String,stack_trace String)  ENGINE =ReplacingMergeTree() PARTITION BY toYYYYMM(startTime) ORDER BY (startTime,status,clusterName,tableName,serverIp,query_id) TTL startTime+INTERVAL 90 DAY;


CREATE DATABASE IF NOT EXISTS k19_distribute;

CREATE TABLE k19_distribute.oss_monitor_log(`region` LowCardinality(String), `starttime_readable` DateTime, `deal_time` Int64, `file_name` String, `file_size` UInt32, `client_ip` String, `server_ip` String, `start_time` Int64, `end_time` Int64, `state` LowCardinality(String), `category` LowCardinality(String), `filter_type` LowCardinality(String), `file_type` LowCardinality(String)) ENGINE =Distributed(clickhouse_tse_local_monitor, k19_ods, ntc_oss_monitor_log_local, rand());
CREATE TABLE k19_distribute.oss_ratelimiter_log(`region` LowCardinality(String),`starttime_readable` DateTime,`start_time` UInt64, `client_host` String,`client_port` String,`remote_host` String,`remote_port` String,`file_type` LowCardinality(String)) ENGINE = Distributed(clickhouse_tse_local_monitor, k19_ods, ntc_oss_ratelimiter_log_local, rand());
-- CREATE TABLE k19_distribute.ntc_oss_monitor_state(`monitor_time` UInt64, `state_code` Int8, `state_msg` String) ENGINE =Distributed(clickhouse_tse_local_monitor, k19_ods, ntc_oss_monitor_state_local, rand());
-- CREATE TABLE k19_distribute.table_oss_category_region_view(`start_time` DateTime,`category` LowCardinality(String),`region` LowCardinality(String),`file_size` UInt32,counts UInt32)ENGINE=Distributed(clickhouse_tse_local_monitor, k19_ods, table_oss_category_region_view_local, rand());
-- CREATE TABLE k19_distribute.table_oss_serverIp_region_view(`start_time` DateTime,`region` LowCardinality(String),`server_ip` LowCardinality(String),`file_size` UInt32,counts UInt32)ENGINE=Distributed(clickhouse_tse_local_monitor, k19_ods, table_oss_server_ip_region_view_local, rand());
-- CREATE TABLE k19_distribute.table_oss_file_name_view(start_time DateTime, file_name String,counts UInt32)ENGINE=Distributed(clickhouse_tse_local_monitor, k19_ods, table_oss_file_name_view_local, rand());

CREATE TABLE k19_distribute.spark_exception_log (`createTime` DateTime, `exceptionDesc` String, `exceptionType` String, `size` Int64, `region` String, `topicName` String, `exceptionNumber` String)  ENGINE =Distributed(clickhouse_tse_local_monitor, k19_ods, spark_exception_log_local, rand());;
CREATE TABLE k19_distribute.spark_monitor_log (`region` String, `job_id` String, `job_name` String, `state` Int8, `start_time` Datetime, `finish_time` Datetime, `url` String, `found_time` Int64)ENGINE =Distributed(clickhouse_tse_local_monitor, k19_ods, spark_monitor_log_local, rand());
CREATE TABLE k19_distribute.yarn_monitor_log (`region` String, `found_time` Int64, `appsSubmitted` Int32, `appsCompleted` Int32, `appsPending` Int32, `appsRunning` Int32, `appsFailed` Int32, `appsKilled` Int32, `reservedMB` Int32, `availableMB` Int32, `allocatedMB` Int32, `reservedVirtualCores` Int32, `availableVirtualCores` Int32, `allocatedVirtualCores` Int32, `containersAllocated` Int32, `containersReserved` Int32, `containersPending` Int32, `totalMB` Int32, `totalVirtualCores` Int32, `totalNodes` Int32, `lostNodes` Int32, `unhealthyNodes` Int32, `decommissionedNodes` Int32, `rebootedNodes` Int32, `activeNodes` Int32)ENGINE =Distributed(clickhouse_tse_local_monitor, k19_ods, yarn_monitor_log_local, rand());


--系统表加上过期时间
ALTER TABLE system.metric_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.part_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.query_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.query_thread_log MODIFY TTL event_time + toIntervalDay(90);
-- ALTER TABLE system.text_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.trace_log MODIFY TTL event_time + toIntervalDay(90);
