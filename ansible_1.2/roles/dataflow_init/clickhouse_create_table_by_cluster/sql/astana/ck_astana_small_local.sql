CREATE DATABASE IF NOT EXISTS k19_ods;
CREATE DATABASE IF NOT EXISTS k19_distribute;

CREATE TABLE k19_ods.ntc_radius_log_local (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String),  code  LowCardinality(String),  nas_ip String,  framed_ip String,  account String,  `s_country` LowCardinality(String), `s_city` String, `s_geo` String, `s_long` Float32, `s_lat` Float32, `d_country` LowCardinality(String), `d_city` String, `d_geo` String, `d_long` Float32, `d_lat` Float32, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4, INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_radius_log_local', '{replica}') PARTITION BY toRelativeWeekNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time)+INTERVAL 90 DAY  SETTINGS index_granularity = 8192, merge_with_ttl_timeout=86400, old_parts_lifetime = 60;

CREATE TABLE k19_ods.ntc_voip_log_local      (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String),   rtp_d_ip String,  rtp_s_ip String,  rtp_d_port Int64,  rtp_s_port Int64,  from_to_store_url String,  to_from_store_url String,  duration String,  call_id String,request_uri String,  calling_account String,  called_account String,  contacts String,  via String,  route String,  record_route String,  user_agent String,  server String, `s_country` LowCardinality(String), `s_city` String, `s_geo` String, `s_long` Float32, `s_lat` Float32, `d_country` LowCardinality(String), `d_city` String, `d_geo` String, `d_long` Float32, `d_lat` Float32, `rtp_key` String, `s_rtp_key` String, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4, INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_voip_log_local', '{replica}') PARTITION BY toRelativeWeekNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time)+INTERVAL 90 DAY  SETTINGS index_granularity = 8192, merge_with_ttl_timeout=86400, old_parts_lifetime = 60;

CREATE TABLE k19_ods.ntc_mail_log_local (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String),  mail_from String,  mail_to String, mail_bcc String, subject String,eml_key String,  eml_file String,  mail_cc String, `s_country` LowCardinality(String), `s_city` String, `s_geo` String, `s_long` Float32, `s_lat` Float32, `d_country` LowCardinality(String), `d_city` String, `d_geo` String, `d_long` Float32, `d_lat` Float32, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4, INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_mail_log_local', '{replica}') PARTITION BY toRelativeWeekNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time)+INTERVAL 90 DAY  SETTINGS index_granularity = 8192, merge_with_ttl_timeout=86400, old_parts_lifetime = 60;

CREATE TABLE k19_ods.ntc_lbs_log_local (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String), longitude String,  latitude String,  coordinate_type LowCardinality(String),  geo_location String, geo_long Float32, geo_lat Float32, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4, INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_lbs_log_local', '{replica}') PARTITION BY toRelativeWeekNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time)+INTERVAL 90 DAY  SETTINGS index_granularity = 8192, merge_with_ttl_timeout=86400, old_parts_lifetime = 60;

CREATE TABLE k19_ods.ntc_nat_log_local (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String), `proto` LowCardinality(String), `operator` Int64, `ip_version` LowCardinality(String), `src_ip` String, `src_natip` String, `dest_ip` String, `dest_natip` String, `src_port` Int64, `src_natport` Int64, `dest_port` Int64, `dest_natport` Int64, `start_time` Int64, `end_time` Int64, `in_totalpkg` Int64, `in_totalbyte` Int64, `out_totalpkg` Int64, `out_totalbyte` Int64, `src_vpn` String, `dst_vpn` String, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4,INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_nat_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192, old_parts_lifetime = 60;

CREATE TABLE k19_ods.ntc_vpn_log_local (`region` LowCardinality(String), `log_id` String, `cfg_id` Int32, `found_time` UInt32, `recv_time` UInt32, `trans_proto` LowCardinality(String), `addr_type` LowCardinality(String), `d_ip` String, `s_ip` String,  `d_port` Int32, `s_port` Int32, `device_id` Int32 CODEC(T64),  `stream_dir` LowCardinality(String), `cap_ip` String, `msisdn` String CODEC(LZ4HC(9)), `imsi` String CODEC(LZ4HC(9)), `imei` String CODEC(LZ4HC(9)), `radius_account` String, `app_lable` LowCardinality(String), `protocol` LowCardinality(String), `tunel_type` LowCardinality(String),`ex_protocol` LowCardinality(String), `hmac` String,`openvpn_encrypt_mode` String,`ssh_version` String,`ssh_software` String,  `s_country` LowCardinality(String), `s_city` String, `s_geo` String, `s_long` Float32, `s_lat` Float32, `d_country` LowCardinality(String), `d_city` String, `d_geo` String, `d_long` Float32, `d_lat` Float32, INDEX s_ip_idx1 s_ip TYPE bloom_filter() GRANULARITY 4, INDEX d_ip_bl_idx d_ip TYPE bloom_filter() GRANULARITY 4) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/ntc_vpn_log_local', '{replica}') PARTITION BY toRelativeWeekNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time)+INTERVAL 90 DAY  SETTINGS index_granularity = 8192, merge_with_ttl_timeout=86400, old_parts_lifetime = 60;

--预聚合表
CREATE TABLE k19_ods.ntc_mail_log_local_group_s_ip (`s_ip` String, `found_time` UInt32 CODEC(T64), `cnt` UInt32 CODEC(T64)) ENGINE = SummingMergeTree(cnt) PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY (s_ip, found_time) TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192, merge_with_ttl_timeout = 86400, old_parts_lifetime = 60, parts_to_delay_insert = 2000, parts_to_throw_insert = 3000;
CREATE MATERIALIZED VIEW k19_ods.ntc_mail_log_local_group_s_ip_view (`s_ip` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Buffer('k19_distribute', 'ntc_mail_log_group_s_ip',  2,  60, 120, 2000000, 4000000, 41943040, 104857600) AS SELECT s_ip, floor(found_time / 300) * 300 AS found_time, 1 AS cnt FROM k19_ods.ntc_mail_log_local;
CREATE TABLE k19_distribute.ntc_mail_log_group_s_ip (`s_ip` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Distributed('clickhouse_tse_local_small', 'k19_ods', 'ntc_mail_log_local_group_s_ip', cityHash64(s_ip));

CREATE TABLE k19_ods.ntc_mail_log_local_group_d_ip (`d_ip` String, `found_time` UInt32 CODEC(T64), `cnt` UInt32 CODEC(T64)) ENGINE = SummingMergeTree(cnt) PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY (d_ip, found_time) TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192, merge_with_ttl_timeout = 86400, old_parts_lifetime = 60, parts_to_delay_insert = 2000, parts_to_throw_insert = 3000;
CREATE MATERIALIZED VIEW k19_ods.ntc_mail_log_local_group_d_ip_view (`d_ip` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Buffer('k19_distribute', 'ntc_mail_log_group_d_ip',  2,  60, 120, 2000000, 4000000, 41943040, 104857600) AS SELECT d_ip, floor(found_time / 300) * 300 AS found_time, 1 AS cnt FROM k19_ods.ntc_mail_log_local;
CREATE TABLE k19_distribute.ntc_mail_log_group_d_ip (`d_ip` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Distributed('clickhouse_tse_local_small', 'k19_ods', 'ntc_mail_log_local_group_d_ip', cityHash64(d_ip));

CREATE TABLE k19_ods.ntc_mail_log_local_group_mail_from (`mail_from` String, `found_time` UInt32 CODEC(T64), `cnt` UInt32 CODEC(T64)) ENGINE = SummingMergeTree(cnt) PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY (mail_from, found_time) TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192, merge_with_ttl_timeout = 86400, old_parts_lifetime = 60, parts_to_delay_insert = 2000, parts_to_throw_insert = 3000;
CREATE MATERIALIZED VIEW k19_ods.ntc_mail_log_local_group_mail_from_view (`mail_from` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Buffer('k19_distribute', 'ntc_mail_log_group_mail_from',  2,  60, 120, 2000000, 4000000, 41943040, 104857600) AS SELECT mail_from, floor(found_time / 300) * 300 AS found_time, 1 AS cnt FROM k19_ods.ntc_mail_log_local;
CREATE TABLE k19_distribute.ntc_mail_log_group_mail_from (`mail_from` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Distributed('clickhouse_tse_local_small', 'k19_ods', 'ntc_mail_log_local_group_mail_from', cityHash64(mail_from));

CREATE TABLE k19_ods.ntc_mail_log_local_group_mail_to (`mail_to` String, `found_time` UInt32 CODEC(T64), `cnt` UInt32 CODEC(T64)) ENGINE = SummingMergeTree(cnt) PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY (mail_to, found_time) TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192, merge_with_ttl_timeout = 86400, old_parts_lifetime = 60, parts_to_delay_insert = 2000, parts_to_throw_insert = 3000;
CREATE MATERIALIZED VIEW k19_ods.ntc_mail_log_local_group_mail_to_view (`mail_to` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Buffer('k19_distribute', 'ntc_mail_log_group_mail_to',  2,  60, 120, 2000000, 4000000, 41943040, 104857600) AS SELECT mail_to, floor(found_time / 300) * 300 AS found_time, 1 AS cnt FROM k19_ods.ntc_mail_log_local;
CREATE TABLE k19_distribute.ntc_mail_log_group_mail_to (`mail_to` String,`found_time` UInt32 CODEC(T64), `cnt` UInt32) ENGINE = Distributed('clickhouse_tse_local_small', 'k19_ods', 'ntc_mail_log_local_group_mail_to', cityHash64(mail_to));

/**

--CREATE TABLE k19_ods.dm_hdr_log_local ( region String,  log_id String,  source_unit_name String,  found_time Int64,  subscriber_id String,  session_key String,  client_ip String,  client_port Int64,  server_ip String,  server_port Int64,  service_id String,  http_method String,  request_header_host String,  uri String,  download_content_length Int64,  upload_content_length Int64,  request_actual_byte_count Int64,  response_actual_byte_count Int64,  response_code Int64,  server_initial_response_time Int64,  duration Int64,  request_header_dnt_x_do_not_track String,  request_header_user_agent String,  request_header_referer String,  response_header_content_type String,  l5protocol String,  client_device_name String,  client_device_class String,  client_device_vendor String,  client_device_model String,  client_device_os_name String,  client_device_os_FullVersion String,  client_device_os_major_version String,  line_id String,  pipe_id String,  vcid String,  cdn String,  imsi String,  imeisv String,  action String,  s_country String,  s_city String,  s_geo String,  s_long Float64, s_lat Float64, d_country String,  d_city String,  d_geo String, d_long Float64, d_lat Float64) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dm_hdr_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time SETTINGS index_granularity = 8192;

**/

/**移动运营商  网络行为分析**/
CREATE TABLE k19_ods.dream_http_log_local (`log_id` String,`action` Int64, `version` Int64, `uri` String, `domain` String, `found_time` UInt32, `msisdn` String, `source_ip` String) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_http_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time))  ORDER BY found_time  TTL toDateTime(found_time)+INTERVAL 90 DAY SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.dream_cdr_log_local (`log_id` String,`record_type` LowCardinality(String), `record_id` Int64, `start_timestamp` String, `calling_party_number` String, `called_party_number` String, `redirecting_number` String, `call_id_number` Int64, `supplementary_services` String, `cause` Int16, `calling_party_category` Int16, `call_duration` Int64, `call_status` Int16, `connected_number` String, `imsi_calling` String, `imei_calling` String, `imsi_called` String, `imei_called` String, `msisdn_calling` String, `msisdn_called` String, `msc_number` String, `vlr_number` String, `location_lac` Int64, `location_cell` Int64, `forwarding_reason` Int16, `roaming_number` String, `ss_code` String, `ussd` String, `operator_id` Int64, `date_and_time` String, `call_direction` Int16, `ll` String, `found_time` UInt32, `recv_time` UInt32,`region` LowCardinality(String), `radio_type` LowCardinality(String), `geo_long` Float32, `geo_lat` Float32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_cdr_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.dream_user_profile_log_local (`log_id` String,`idOfSubscriber` String, `found_time` UInt32, `name` String, `msisdn` String, `imsi` String, `imei` String, `addressOfRegistration` String, `passport` String,passport_number String, `dateOfBirth` String, `inn` String, `contactPerson` String, `contactPhonenumber` String, `dateOfSimActivation` String, `dateOfSimStatusInit` String, `statusOfSim` LowCardinality(String), `radio_type` LowCardinality(String), `dateAndTimeOfAct` String, `subscriberActivationDate` String, `bin` String, `ndsCertificate` String, `contractConclusionDate` String, `email` String,`region` LowCardinality(String)) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_user_profile_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time  TTL toDateTime(found_time)+INTERVAL 90 DAY SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.dream_vlr_log_local (`log_id` String,`msisdn` String, `imsi` String, `imei` String, `mnc` String, `mcc` String, `lac` Int64, `cell` Int64, `old_location_lac` Int64, `old_location_cell` Int64, `date_and_time` String, `location_update_type` LowCardinality(String), `ll` String, `ll_old` String, `switchgear_type` LowCardinality(String), `found_time` UInt32, `recv_time` UInt32,`region` LowCardinality(String), `radio_type` LowCardinality(String), `geo_long` Float32, `geo_lat` Float32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_vlr_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time  TTL toDateTime(found_time)+INTERVAL 90 DAY SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.dream_sms_log_local(`log_id` String,`record_type` LowCardinality(String), `record_id` Int64, `start_timestamp` String, `calling_party_number` String, `called_party_number` String, `redirecting_number` String, `call_id_number` String, `supplementary_services` String, `cause` Int16, `calling_party_category` Int16, `call_duration` Int64, `call_status` Int16, `connected_number` String, `imsi_calling` String, `imei_calling` String, `imsi_called` String, `imei_called` String, `msisdn_calling` String, `msisdn_called` String, `msc_number` String, `vlr_number` String, `location_lac` Int64, `location_cell` Int64, `forwarding_reason` Int16, `roaming_number` String, `ss_code` String, `ussd` String, `operator_id` Int64, `date_and_time` String, `call_direction` Int16, `ll` String, `found_time` UInt32, `recv_time` UInt32,`region` LowCardinality(String), `radio_type` LowCardinality(String), `geo_long` Float32, `geo_lat` Float32 ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_sms_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time TTL toDateTime(found_time) + toIntervalDay(90) SETTINGS index_granularity = 8192;
CREATE TABLE k19_ods.dream_email_log_local (`log_id` String,`found_time` UInt32, `msisdn_calling` String, `protocol` String, `source_ip` String, `source_port` Int64, `dst_ip` String, `dst_port` Int64, `msg_id` Int64, `subject` String, `from` String, `to` String, `reply_to` String, `cc` String, `bcc` String, `received` String, `return_path` String, `comments` String, `in_reply_to` String, `content_type` String, `filenames` String) ENGINE = ReplicatedMergeTree('/clickhouse/tables/astana/{shard}/dream_email_log_local', '{replica}') PARTITION BY toRelativeDayNum(toDateTime(found_time)) ORDER BY found_time  TTL toDateTime(found_time)+INTERVAL 90 DAY SETTINGS index_granularity = 8192;


-- /**网络行为分析**/
-- CREATE DATABASE IF NOT EXISTS zt;
--
-- -- DROP TABLE IF EXISTS zt.cdr_local;
-- CREATE TABLE zt.cdr_local (   record_type String,   record_id String,   found_time Int64,   calling_party_number String,   called_party_number String,   redirecting_number String,   call_id_number String,   supplementary_services String,   cause String,   calling_party_category String,   call_duration String,   call_status String,   connected_number String,   imsi_calling String,   imei_calling String,   imsi_called String,   imei_called String,   msisdn_calling String,   msisdn_called String,   msc_number String,   vlr_number String,   location_lac String,   location_cell String,   forwarding_reason String,   roaming_number String,   ss_code String,   ussd String,   operator_id String,   date_and_time Int64,   call_direction String,   ll String ) ENGINE = MergeTree PARTITION BY toRelativeHourNum(toDateTime(found_time)) ORDER BY   found_time SETTINGS index_granularity = 8192;
--
-- -- DROP TABLE IF EXISTS zt.email_local ;
-- CREATE TABLE zt.email_local (   found_time Int64,   msisdn_calling String,   protocol String,   source_ip String,   source_port Int64,   dst_ip String,   dst_port Int64,   msg_id Int64,   subject String,   from String, to String, reply_to String, cc String, bcc String, received String, return_path String, comments String, in_reply_to String, content_type String, filenames String ) ENGINE = MergeTree PARTITION BY toRelativeHourNum(toDateTime(found_time)) ORDER BY   found_time SETTINGS index_granularity = 8192;
--
--
-- -- DROP TABLE IF EXISTS zt.http_local ;
-- CREATE TABLE zt.http_local (   action Int64,   version Int64,   uri String,   domain String,   found_time Int64,   msisdn String,   source_ip String ) ENGINE = MergeTree PARTITION BY toRelativeHourNum(toDateTime(found_time)) ORDER BY   found_time SETTINGS index_granularity = 8192;
--
-- -- DROP TABLE IF EXISTS zt.loc_local;
-- CREATE TABLE zt.loc_local (   msisdn String,   lac Int64,   cell Int64,   found_time Int64,   loc_type Int64,   imsi String,   imei String,   ll String,   switchgear_type String ) ENGINE = MergeTree PARTITION BY toRelativeHourNum(toDateTime(found_time)) ORDER BY   found_time SETTINGS index_granularity = 8192;

--每张表每小时新增
CREATE MATERIALIZED VIEW k19_ods.ck_hour_increament_materialized_view_local (`eventtime` DateTime, `table` String, `rows` UInt64) ENGINE = SummingMergeTree(rows) PARTITION BY toYYYYMM(eventtime) ORDER BY (eventtime, table) TTL eventtime+INTERVAL 90 DAY SETTINGS index_granularity = 8192 POPULATE AS SELECT toDateTime(toRelativeHourNum(min(event_time)) * 3600) AS eventtime, concat(database, '.', table) AS table, sum(rows) AS rows FROM system.part_log WHERE event_type = 1 GROUP BY database, table, toRelativeHourNum(event_time) ORDER BY database ASC, table ASC, toRelativeHourNum(event_time) ASC;
--每张表每天新增
CREATE MATERIALIZED VIEW k19_ods.ck_day_increament_materialized_view_local (`eventtime` DateTime, `table` String, `rows` UInt64) ENGINE = SummingMergeTree(rows) PARTITION BY toYYYYMM(eventtime) ORDER BY (eventtime, table) TTL eventtime+INTERVAL 90 DAY SETTINGS index_granularity = 8192 POPULATE AS SELECT toDate(event_time) AS eventtime, concat(database, '.', table) AS table, sum(rows) AS rows FROM system.part_log WHERE event_type = 1 GROUP BY database, table, toDate(event_time) ORDER BY database ASC, table ASC, toDate(event_time) ASC;

----非系统表非视图非SELECT 1，非optimize剩下的insert和select语句并且加上了sql执行所在机器的serverIp
CREATE TABLE k19_ods.ck_slow_query_log_local (`eventDate` Date, `startTime` DateTime, `status` LowCardinality(String), `useSeconds` Float64, `readRows` UInt64, `resultRows` UInt64, `writeRows` UInt64, `writtenMB` Float64, `memoryUsageMB` Float64, `tableName` LowCardinality(String),`clusterName` LowCardinality(String), `serverName` LowCardinality(String), `serverIp` LowCardinality(String), `initial_query_id` UUID, `query_id` UUID, `queryFromHost` LowCardinality(String), `query` String,exception String,stack_trace String)  ENGINE =ReplacingMergeTree() PARTITION BY toYYYYMM(startTime) ORDER BY (startTime,status,clusterName,tableName,serverIp,query_id) TTL startTime+INTERVAL 90 DAY;

--系统表加上过期时间
ALTER TABLE system.metric_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.part_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.query_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.query_thread_log MODIFY TTL event_time + toIntervalDay(90);
-- ALTER TABLE system.text_log MODIFY TTL event_time + toIntervalDay(90);
ALTER TABLE system.trace_log MODIFY TTL event_time + toIntervalDay(90);
